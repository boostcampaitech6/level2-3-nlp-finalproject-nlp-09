{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "import random\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed:int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RE_Dataset(torch.utils.data.Dataset):\n",
    "  \"\"\" Dataset êµ¬ì„±ì„ ìœ„í•œ class.\"\"\"\n",
    "  def __init__(self, pair_dataset, labels):\n",
    "    self.pair_dataset = pair_dataset\n",
    "    self.labels = labels\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "    item['labels'] = torch.tensor(self.labels[idx])\n",
    "    return item\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "  \n",
    "def preprocessing_dataset(dataset):\n",
    "  \"\"\" ì²˜ìŒ ë¶ˆëŸ¬ì˜¨ csv íŒŒì¼ì„ ì›í•˜ëŠ” í˜•íƒœì˜ DataFrameìœ¼ë¡œ ë³€ê²½ ì‹œì¼œì¤ë‹ˆë‹¤.\"\"\"\n",
    "  out_dataset = pd.DataFrame({'url':dataset['url'], 'context':dataset['context'], 'main':dataset['main'], 'detail':dataset['detail']})\n",
    "  return out_dataset\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "  \"\"\" csv íŒŒì¼ì„ ê²½ë¡œì— ë§¡ê²Œ ë¶ˆëŸ¬ ì˜µë‹ˆë‹¤. \"\"\"\n",
    "  dataset = pd.read_csv(dataset_dir)\n",
    "  dataset = preprocessing_dataset(dataset)\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "def tokenized_dataset(context, tokenizer):\n",
    "  \"\"\" tokenizerì— ë”°ë¼ sentenceë¥¼ tokenizing í•©ë‹ˆë‹¤.\"\"\"\n",
    "  tokenized_context = tokenizer(context,return_tensors=\"pt\", padding=True, truncation=True, max_length=256, add_special_tokens=True,)\n",
    "  return tokenized_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klue_re_micro_f1_for_main(preds, labels):\n",
    "    label_list = ['ê¸°ì¨', 'ìŠ¬í””', 'ì‹«ì–´í•¨(ìƒíƒœ)', 'ë¶„ë…¸', 'ë¯¸ì›€(ìƒëŒ€ë°©)', 'ë‘ë ¤ì›€', 'ìˆ˜ì¹˜ì‹¬', 'ìš•ë§', 'ì‚¬ë‘', 'ì¤‘ë¦½']\n",
    "    label_indices = list(range(len(label_list)))\n",
    "    return sklearn.metrics.f1_score(labels, preds, average=\"micro\", labels=label_indices) * 100.0\n",
    "\n",
    "def klue_re_auprc_for_main(probs, labels):\n",
    "    labels = np.eye(10)[labels]\n",
    "\n",
    "    score = np.zeros((10,))\n",
    "    for c in range(10):\n",
    "        targets_c = labels.take([c], axis=1).ravel()\n",
    "        preds_c = probs.take([c], axis=1).ravel()\n",
    "        precision, recall, _ = sklearn.metrics.precision_recall_curve(targets_c, preds_c)\n",
    "        score[c] = sklearn.metrics.auc(recall, precision)\n",
    "    return np.average(score) * 100.0\n",
    "\n",
    "def klue_re_micro_f1_for_detail(preds, labels):\n",
    "    label_list = ['ë§Œì¡±ê°', 'ë¬´ê¸°ë ¥', 'ì¦ê±°ì›€', 'ë‹µë‹µí•¨', 'íƒ€ì˜¤ë¦„', 'ë¶ˆì¾Œ', 'ìë‘ìŠ¤ëŸ¬ì›€', 'ì ˆë§', 'ì¹˜ì‚¬í•¨', 'ê±±ì •', 'ë¶€ë„ëŸ¬ì›€', 'ê¶ê¸ˆí•¨', 'ë†€ëŒ', 'ì•„ì‰¬ì›€', 'ì‹«ì¦', 'ê³µê°', 'ê°ë™', 'ëƒ‰ë‹´', 'ê²½ë©¸',\n",
    "                  'ë§¤ë ¥ì ', 'ë°˜ê°€ì›€', 'ë¶ˆë§Œ', 'ì‹¤ë§', 'ë¯¸ì•ˆí•¨', 'ë‹¤ì •í•¨', 'ê³µí¬', 'ì–µìš¸í•¨', 'ë‚œì²˜í•¨', 'ë‚ ì¹´ë¡œì›€', 'ë¶ˆì‹ ê°', 'ë™ì •(ìŠ¬í””)', 'ë¶ˆí¸í•¨', 'ì•„í””', 'ê³ ë§ˆì›€', 'í˜¸ê°', 'ê·€ì¤‘í•¨', 'ê¸°ëŒ€ê°', 'ê³ í†µ',\n",
    "                  'ìˆ˜ì¹˜ì‹¬', 'ì´ˆì¡°í•¨', 'ì›ë§', 'ìœ„ì¶•ê°', 'í›„íšŒ', 'ìš•ì‹¬', 'ì‹œê¸°ì‹¬', 'ì•ˆì •ê°', 'ë„ˆê·¸ëŸ¬ì›€', 'ì™¸ë©´', 'ê·¸ë¦¬ì›€', 'í—ˆë§', 'í¸ì•ˆí•¨', 'ì‹ ëª…ë‚¨', 'ë¹„ìœ„ìƒí•¨', 'ë°˜ê°', 'ì£„ì±…ê°', 'ì•„ë¥¸ê±°ë¦¼', 'ì™¸ë¡œì›€',\n",
    "                  'ì„œë¨¹í•¨', 'ìì‹ ê°', 'ë‘ê·¼ê±°ë¦¼', 'ì‹¬ì‹¬í•¨', 'ê°ˆë“±', 'ì‹ ë¢°ê°', 'ì—´ì •ì ì¸']\n",
    "    label_indices = list(range(len(label_list)))\n",
    "    return sklearn.metrics.f1_score(labels, preds, average=\"micro\", labels=label_indices) * 100.0\n",
    "\n",
    "def klue_re_auprc_for_detail(probs, labels):\n",
    "    labels = np.eye(64)[labels]\n",
    "\n",
    "    score = np.zeros((64,))\n",
    "    for c in range(64):\n",
    "        targets_c = labels.take([c], axis=1).ravel()\n",
    "        preds_c = probs.take([c], axis=1).ravel()\n",
    "        precision, recall, _ = sklearn.metrics.precision_recall_curve(targets_c, preds_c)\n",
    "        score[c] = sklearn.metrics.auc(recall, precision)\n",
    "    return np.average(score) * 100.0\n",
    "\n",
    "def compute_metrics_for_main(pred):\n",
    "  \"\"\" validationì„ ìœ„í•œ metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  f1 = klue_re_micro_f1_for_main(preds, labels)\n",
    "  auprc = klue_re_auprc_for_main(probs, labels)\n",
    "  acc = accuracy_score(labels, preds)\n",
    "\n",
    "  return {\n",
    "      'micro f1 score': f1,\n",
    "      'auprc' : auprc,\n",
    "      'accuracy': acc,\n",
    "  }\n",
    "\n",
    "def compute_metrics_for_detail(pred):\n",
    "  \"\"\" validationì„ ìœ„í•œ metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  f1 = klue_re_micro_f1_for_detail(preds, labels)\n",
    "  auprc = klue_re_auprc_for_detail(probs, labels)\n",
    "  acc = accuracy_score(labels, preds)\n",
    "\n",
    "  return {\n",
    "      'micro f1 score': f1,\n",
    "      'auprc' : auprc,\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./detail_to_num.pkl', 'rb') as f:\n",
    "  detail_to_num = pickle.load(f)\n",
    "with open('./num_to_detail.pkl', 'rb') as f:\n",
    "  num_to_detail = pickle.load(f)\n",
    "with open('./main_to_num.pkl', 'rb') as f:\n",
    "  main_to_num = pickle.load(f)\n",
    "with open('./num_to_main.pkl', 'rb') as f:\n",
    "  num_to_main = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'google-bert/bert-base-multilingual-uncased'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>context</th>\n",
       "      <th>main</th>\n",
       "      <th>detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://x.com/1hhaa_/status/175373236692813461...</td>\n",
       "      <td>ë³´ëŠ”ë™ì•ˆ ë„ˆë¬´ í–‰ë³µí–ˆê³  ì´ˆì½œë ›ì´ ë„ˆë¬´ ë¨¹ê³ ì‹¶ì—ˆê³  í‹°ëª¨ì‹œê°€ ì˜ìƒê²¼ê³  ìš¸ì–´!!í•˜ëŠ”ë¶€ë¶„ì´...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ë§Œì¡±ê°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://x.com/makki_home/status/17552181165049...</td>\n",
       "      <td>ì–´ë¦´ ë•Œ ê°€ ë³´ê³  ë¹•ìŠ¤ëŠ” ê±°ì˜ ì²˜ìŒì¸ë°(ê¸°ì–µì— ì—†ìŒ) ì§€ê¸ˆ ë”¸ê¸°ì¶•ì œ ê¸°ê°„ì´ë¼ ë§Œì¡±ìŠ¤...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ë§Œì¡±ê°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://x.com/302NOW/status/175539358101844788...</td>\n",
       "      <td>ë¯¸ë¦¬ ê³„ì¢Œë¡œ í™˜ì „í•´ë‘” ëˆì„ í•´ì™¸ì—ì„œ í™˜ì „ìˆ˜ìˆ˜ë£Œ ì—†ì´ ì¸ì¶œ ê°€ëŠ¥í•œ íŠ¸ë ˆë¸”ë¡œê·¸ë¼ëŠ” ì¹´ë“œ...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ë§Œì¡±ê°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://x.com/Hassen_cos/status/17556459885792...</td>\n",
       "      <td>ìš”ì¦˜ ë²ˆì•„ì›ƒë„ ìê¾¸ ì˜¬ë¼ì˜¤ê³  ë¬´ê¸°ë ¥í•´ì„œ ì¢…ê°•í•˜ê³  êµë¥˜í•˜ê¸°ë„ ë²„ê±°ìš´ ìƒíƒœê°€ ì™€ë¶€ë €ìœ¼ìš”ã… ã… </td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "      <td>ë¬´ê¸°ë ¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://x.com/ssosohae1/status/175618221059468...</td>\n",
       "      <td>í¬ë¼ì„ì”¬ ì¥ë˜¥ë¯¼ì´ ë²”í–‰ ë„êµ¬ ì°¾ìœ¼ë ¤ê³  í™”ì¥ì‹¤ íƒ±í¬ ë’¤ì§€ëŠ”ë° ê±°ê¸°ì— ì§„ì§œ ë˜¥ ë„£ì–´ë†“ì€...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ì¦ê±°ì›€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://x.com/1hhaa_/status/175373236692813461...   \n",
       "1  https://x.com/makki_home/status/17552181165049...   \n",
       "2  https://x.com/302NOW/status/175539358101844788...   \n",
       "3  https://x.com/Hassen_cos/status/17556459885792...   \n",
       "4  https://x.com/ssosohae1/status/175618221059468...   \n",
       "\n",
       "                                             context main detail  \n",
       "0  ë³´ëŠ”ë™ì•ˆ ë„ˆë¬´ í–‰ë³µí–ˆê³  ì´ˆì½œë ›ì´ ë„ˆë¬´ ë¨¹ê³ ì‹¶ì—ˆê³  í‹°ëª¨ì‹œê°€ ì˜ìƒê²¼ê³  ìš¸ì–´!!í•˜ëŠ”ë¶€ë¶„ì´...   ê¸°ì¨    ë§Œì¡±ê°  \n",
       "1  ì–´ë¦´ ë•Œ ê°€ ë³´ê³  ë¹•ìŠ¤ëŠ” ê±°ì˜ ì²˜ìŒì¸ë°(ê¸°ì–µì— ì—†ìŒ) ì§€ê¸ˆ ë”¸ê¸°ì¶•ì œ ê¸°ê°„ì´ë¼ ë§Œì¡±ìŠ¤...   ê¸°ì¨    ë§Œì¡±ê°  \n",
       "2  ë¯¸ë¦¬ ê³„ì¢Œë¡œ í™˜ì „í•´ë‘” ëˆì„ í•´ì™¸ì—ì„œ í™˜ì „ìˆ˜ìˆ˜ë£Œ ì—†ì´ ì¸ì¶œ ê°€ëŠ¥í•œ íŠ¸ë ˆë¸”ë¡œê·¸ë¼ëŠ” ì¹´ë“œ...   ê¸°ì¨    ë§Œì¡±ê°  \n",
       "3  ìš”ì¦˜ ë²ˆì•„ì›ƒë„ ìê¾¸ ì˜¬ë¼ì˜¤ê³  ë¬´ê¸°ë ¥í•´ì„œ ì¢…ê°•í•˜ê³  êµë¥˜í•˜ê¸°ë„ ë²„ê±°ìš´ ìƒíƒœê°€ ì™€ë¶€ë €ìœ¼ìš”ã… ã…     ìŠ¬í””    ë¬´ê¸°ë ¥  \n",
       "4  í¬ë¼ì„ì”¬ ì¥ë˜¥ë¯¼ì´ ë²”í–‰ ë„êµ¬ ì°¾ìœ¼ë ¤ê³  í™”ì¥ì‹¤ íƒ±í¬ ë’¤ì§€ëŠ”ë° ê±°ê¸°ì— ì§„ì§œ ë˜¥ ë„£ì–´ë†“ì€...   ê¸°ì¨    ì¦ê±°ì›€  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data('../data/reviewed_emotion_0311.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = [main_to_num[value] for value in df.main]\n",
    "detail = [detail_to_num[value] for value in df.detail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = tokenized_dataset(df['context'].to_list(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split íŠ¹ì • labelì´ 1ê°œ ë°–ì— ì—†ì–´ì„œ stratify ë¶ˆê°€\n",
    "# context_train, context_test, main_label_train, main_label_test, detail_label_train, detail_label_test = train_test_split(df['context'], main, detail, test_size=0.3)\n",
    "\n",
    "# RE_main_train_dataset = RE_Dataset(context_train, main_label_train)\n",
    "# RE_main_test_dataset = RE_Dataset(context_test, main_label_test)\n",
    "\n",
    "# RE_detail_train_dataset = RE_Dataset(context_train, detail_label_train)\n",
    "# RE_detail_test_dataset = RE_Dataset(context_test, detail_label_test)\n",
    "\n",
    "# split ì—†ì´\n",
    "RE_main_dataset = RE_Dataset(context, main)\n",
    "RE_detail_dataset = RE_Dataset(context, detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config_for_main =  AutoConfig.from_pretrained(MODEL_NAME)\n",
    "model_config_for_main.num_labels = len(df['main'].unique())\n",
    "\n",
    "model_config_for_detail =  AutoConfig.from_pretrained(MODEL_NAME)\n",
    "model_config_for_detail.num_labels = len(df['detail'].unique())\n",
    "\n",
    "model_for_main =  AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=model_config_for_main)\n",
    "model_for_detail =  AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=model_config_for_detail)\n",
    "model_for_main.to(device)\n",
    "model_for_detail.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir='results_for_main',          # output directory\n",
    "  save_steps=500,                 # model saving step.\n",
    "  num_train_epochs=20,              # total number of training epochs\n",
    "  learning_rate=1e-5,               # learning_rate\n",
    "  per_device_train_batch_size=16,  # batch size per device during training\n",
    "  per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "  warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "  weight_decay=0.01,               # strength of weight decay\n",
    "  evaluation_strategy='steps', # evaluation strategy to adopt during training\n",
    "                              # `no`: No evaluation during training.\n",
    "                              # `steps`: Evaluate every `eval_steps`.\n",
    "                              # `epoch`: Evaluate every end of epoch.\n",
    "  logging_steps=500,              # log saving step.\n",
    "  eval_steps = 500,            # evaluation step.\n",
    "  load_best_model_at_end = True\n",
    "  )\n",
    "trainer_for_main = Trainer(\n",
    "  model=model_for_main,                         # the instantiated ğŸ¤— Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=RE_main_dataset,         # training dataset\n",
    "  eval_dataset=RE_main_dataset,             # evaluation dataset\n",
    "  compute_metrics=compute_metrics_for_main         # define metrics function\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir='results_for_detail',          # output directory\n",
    "  save_steps=500,                 # model saving step.\n",
    "  num_train_epochs=20,              # total number of training epochs\n",
    "  learning_rate=1e-5,               # learning_rate\n",
    "  per_device_train_batch_size=16,  # batch size per device during training\n",
    "  per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "  warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "  weight_decay=0.01,               # strength of weight decay\n",
    "  evaluation_strategy='steps', # evaluation strategy to adopt during training\n",
    "                              # `no`: No evaluation during training.\n",
    "                              # `steps`: Evaluate every `eval_steps`.\n",
    "                              # `epoch`: Evaluate every end of epoch.\n",
    "  logging_steps=500,              # log saving step\n",
    "  eval_steps = 500,            # evaluation step.\n",
    "  load_best_model_at_end = True\n",
    "  )\n",
    "\n",
    "trainer_for_detail = Trainer(\n",
    "  model=model_for_detail,                         # the instantiated ğŸ¤— Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=RE_detail_dataset,         # training dataset\n",
    "  eval_dataset=RE_detail_dataset,             # evaluation dataset\n",
    "  compute_metrics=compute_metrics_for_detail         # define metrics function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='398' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 398/1300 08:29 < 19:19, 0.78 it/s, Epoch 6.11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_for_main.train()\n",
    "trainer_for_detail.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aihub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, tokenized_sent, device):\n",
    "  \"\"\"\n",
    "    test datasetì„ DataLoaderë¡œ ë§Œë“¤ì–´ ì¤€ í›„,\n",
    "    batch_sizeë¡œ ë‚˜ëˆ  modelì´ ì˜ˆì¸¡ í•©ë‹ˆë‹¤.\n",
    "  \"\"\"\n",
    "  dataloader = DataLoader(tokenized_sent, batch_size=16, shuffle=False)\n",
    "  model.eval()\n",
    "  output_pred = []\n",
    "  output_prob = []\n",
    "  for i, data in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "      outputs = model(\n",
    "          input_ids=data['input_ids'].to(device),\n",
    "          attention_mask=data['attention_mask'].to(device),\n",
    "          token_type_ids=data['token_type_ids'].to(device)\n",
    "          )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "  return np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/aihub.json') as aihub:\n",
    "  parsed_json = json.load(aihub)\n",
    "  \n",
    "aihub_context = [data['talk']['content']['HS01'] for data in parsed_json]\n",
    "aihub_label = [0] * len(aihub_context)\n",
    "aihub_df = pd.DataFrame({'context':aihub_context, 'label':aihub_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir='results',          # output directory\n",
    "  save_steps=500,                 # model saving step.\n",
    "  num_train_epochs=20,              # total number of training epochs\n",
    "  learning_rate=1e-5,               # learning_rate\n",
    "  per_device_train_batch_size=16,  # batch size per device during training\n",
    "  per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "  warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "  weight_decay=0.01,               # strength of weight decay\n",
    "  evaluation_strategy='steps', # evaluation strategy to adopt during training\n",
    "                              # `no`: No evaluation during training.\n",
    "                              # `steps`: Evaluate every `eval_steps`.\n",
    "                              # `epoch`: Evaluate every end of epoch.\n",
    "  logging_steps=500,              # log saving step.\n",
    "  eval_steps = 500,            # evaluation step.\n",
    "  load_best_model_at_end = True\n",
    "  )\n",
    "\n",
    "\n",
    "learning_count = 10\n",
    "cut_count = len(aihub_label) // learning_count\n",
    "\n",
    "for n in range(learning_count):\n",
    "  print(f'{n + 1}ë²ˆì§¸ ì‹œì‘')\n",
    "  aihub_tokenized_context = tokenized_dataset(aihub_df['context'].to_list(), tokenizer)\n",
    "  aihub_label = aihub_df['label'].to_list()\n",
    "\n",
    "  RE_test_dataset = RE_Dataset(aihub_tokenized_context, aihub_label)\n",
    "\n",
    "  print('ì˜ˆì¸¡ ì‹œì‘')\n",
    "  main_pred_answer, main_output_prob = inference(model_for_main, RE_test_dataset, device) # modelì—ì„œ class ì¶”ë¡ \n",
    "  detail_pred_answer, detail_output_prob = inference(model_for_detail, RE_test_dataset, device) # modelì—ì„œ class ì¶”ë¡ \n",
    "  print('ì˜ˆì¸¡ ì¢…ë£Œ')\n",
    "  # main_pred_answer_label = [num_to_main[value] for value in main_pred_answer]\n",
    "  # detail_pred_answer_label = [num_to_detail[value] for value in detail_pred_answer]\n",
    "  aihub_df['main_pred'] = main_pred_answer\n",
    "  aihub_df['main_prob'] = main_output_prob\n",
    "  aihub_df['main_prob'] = aihub_df['main_prob'].apply(lambda x: max(x))\n",
    "  aihub_df['detail_pred'] = detail_pred_answer\n",
    "  aihub_df['detail_prob'] = detail_output_prob\n",
    "  aihub_df['detail_prob'] = aihub_df['detail_prob'].apply(lambda x: max(x))\n",
    "  aihub_df['prob_mean'] = aihub_df.apply(lambda row: (row['main_prob'] * row['detail_prob']) / 2, axis=1)\n",
    "  aihub_df = aihub_df.sort_values(by='prob_mean', ascending=False)\n",
    "\n",
    "  new_learning_data = aihub_df.iloc[:cut_count]\n",
    "  aihub_df = aihub_df.iloc[cut_count:]\n",
    "\n",
    "  tokenized_context = tokenized_dataset(new_learning_data['context'].to_list(), tokenizer)\n",
    "  NEW_main_train_dataset = RE_Dataset(tokenized_context, new_learning_data['main_pred'].to_list())\n",
    "  NEW_detail_train_dataset = RE_Dataset(tokenized_context, new_learning_data['detail_pred'].to_list())\n",
    "\n",
    "  trainer_for_main = Trainer(\n",
    "    model=model_for_main,                         # the instantiated ğŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=NEW_main_train_dataset,         # training dataset\n",
    "    eval_dataset=RE_main_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics_for_main         # define metrics function\n",
    "  )\n",
    "\n",
    "  trainer_for_detail = Trainer(\n",
    "    model=model_for_detail,                         # the instantiated ğŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=NEW_detail_train_dataset,         # training dataset\n",
    "    eval_dataset=RE_detail_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics_for_detail         # define metrics function\n",
    "  )\n",
    "  \n",
    "  print('í•™ìŠµ ì‹œì‘')\n",
    "  trainer_for_main.train()\n",
    "  trainer_for_detail.train()\n",
    "  print('í•™ìŠµ ì¢…ë£Œ')\n",
    "  print(f'{n + 1}ë²ˆì§¸ ì¢…ë£Œ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
