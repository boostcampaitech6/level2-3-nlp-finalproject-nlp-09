dataset:
  type: B # A(감성 대화) or B(공감 대화)
  pathA: ../data/dataset.parquet
  pathB: ../data/*/*/*.json
train_params:
  model_name: CurtisJeon/OrionStarAI-Orion-14B-Base-4bit
  model_4bit: True
  load_adapter: True
  adapter_path: ../models/best_adapter_e9 # if load_adapter is true, load this adapter to model
  output_dir: ../checkpoints/lora/  # checkpoint save dir
  save_dir: ../models/  # final model save
  lr_rate: 2e-4
  lr_scheduler_type: cosine
  weight_decay: 0.001
  max_grad_norm: 0.3
  num_train_epochs: 5
  batch_size: 1
  gradient_accumulation_steps: 8
  fp16: True
  bf16: False
  optim: paged_adamw_32bit
  device_map: auto
lora:
  lora_r: 8
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules: [q_proj, o_proj, k_proj, v_proj, gate_proj, up_proj, down_proj]
quantization:
  use_4bit: True
  bnb_4bit_compute_dtype: float16
  bnb_4bit_quant_type: nf4
  use_nested_quant: False